{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWhIezfOLfGn",
        "outputId": "942fc223-bf0d-4cf3-e637-6f55a0c6a5e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Resultados salvos em results.txt\n",
            "Matriz de ConfusÃ£o\n",
            "==================\n",
            "                Pred: Pos   Pred: Neg\n",
            "Real: Pos   ->   VP=90      FN=20    \n",
            "Real: Neg   ->   FP=10      VN=50    \n",
            "\n",
            "MÃ©tricas\n",
            "========\n",
            "AcurÃ¡cia: 0.8235\n",
            "PrecisÃ£o (PPV): 0.9000\n",
            "Recall / Sensibilidade (TPR): 0.8182\n",
            "Especificidade (TNR): 0.8333\n",
            "F1-Score: 0.8571\n",
            "Fallout (FPR): 0.1667\n",
            "NPV: 0.7143\n",
            "PrevalÃªncia: 0.6471\n",
            "Total: 170\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# MÃ©tricas de ClassificaÃ§Ã£o\n",
        "# ============================\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Tuple\n",
        "import math\n",
        "\n",
        "@dataclass\n",
        "class ConfusionMatrix:\n",
        "    VP: int  # Verdadeiros Positivos (TP)\n",
        "    VN: int  # Verdadeiros Negativos (TN)\n",
        "    FP: int  # Falsos Positivos (FP)\n",
        "    FN: int  # Falsos Negativos (FN)\n",
        "\n",
        "    @property\n",
        "    def total(self) -> int:\n",
        "        return self.VP + self.VN + self.FP + self.FN\n",
        "\n",
        "def accuracy(cm: ConfusionMatrix) -> float:\n",
        "    # (VP + VN) / (VP + VN + FP + FN)\n",
        "    denom = cm.total\n",
        "    return (cm.VP + cm.VN) / denom if denom else float(\"nan\")\n",
        "\n",
        "def precision(cm: ConfusionMatrix) -> float:\n",
        "    # VP / (VP + FP)\n",
        "    denom = (cm.VP + cm.FP)\n",
        "    return cm.VP / denom if denom else float(\"nan\")\n",
        "\n",
        "def recall(cm: ConfusionMatrix) -> float:\n",
        "    # VP / (VP + FN)  (sensibilidade)\n",
        "    denom = (cm.VP + cm.FN)\n",
        "    return cm.VP / denom if denom else float(\"nan\")\n",
        "\n",
        "def specificity(cm: ConfusionMatrix) -> float:\n",
        "    # VN / (VN + FP)\n",
        "    denom = (cm.VN + cm.FP)\n",
        "    return cm.VN / denom if denom else float(\"nan\")\n",
        "\n",
        "def f1_score(cm: ConfusionMatrix) -> float:\n",
        "    p = precision(cm)\n",
        "    r = recall(cm)\n",
        "    denom = (p + r)\n",
        "    return 2 * p * r / denom if denom else float(\"nan\")\n",
        "\n",
        "def fallout(cm: ConfusionMatrix) -> float:\n",
        "    # FP rate = FP / (FP + VN)\n",
        "    denom = (cm.FP + cm.VN)\n",
        "    return cm.FP / denom if denom else float(\"nan\")\n",
        "\n",
        "def npv(cm: ConfusionMatrix) -> float:\n",
        "    # Valor Preditivo Negativo = VN / (VN + FN)\n",
        "    denom = (cm.VN + cm.FN)\n",
        "    return cm.VN / denom if denom else float(\"nan\")\n",
        "\n",
        "def prevalence(cm: ConfusionMatrix) -> float:\n",
        "    # (VP + FN) / total\n",
        "    return (cm.VP + cm.FN) / cm.total if cm.total else float(\"nan\")\n",
        "\n",
        "def metrics_summary(cm: ConfusionMatrix) -> Dict[str, float]:\n",
        "    return {\n",
        "        \"AcurÃ¡cia\": accuracy(cm),\n",
        "        \"PrecisÃ£o (PPV)\": precision(cm),\n",
        "        \"Recall / Sensibilidade (TPR)\": recall(cm),\n",
        "        \"Especificidade (TNR)\": specificity(cm),\n",
        "        \"F1-Score\": f1_score(cm),\n",
        "        \"Fallout (FPR)\": fallout(cm),\n",
        "        \"NPV\": npv(cm),\n",
        "        \"PrevalÃªncia\": prevalence(cm),\n",
        "        \"Total\": cm.total,\n",
        "    }\n",
        "\n",
        "def pretty_print(cm: ConfusionMatrix, metrics: Dict[str, float]) -> None:\n",
        "    # Matriz de confusÃ£o formatada\n",
        "    print(\"Matriz de ConfusÃ£o\")\n",
        "    print(\"==================\")\n",
        "    print(f\"                Pred: Pos   Pred: Neg\")\n",
        "    print(f\"Real: Pos   ->   VP={cm.VP:<6}  FN={cm.FN:<6}\")\n",
        "    print(f\"Real: Neg   ->   FP={cm.FP:<6}  VN={cm.VN:<6}\\n\")\n",
        "\n",
        "    print(\"MÃ©tricas\")\n",
        "    print(\"========\")\n",
        "    for k, v in metrics.items():\n",
        "        if k == \"Total\":\n",
        "            print(f\"{k}: {v}\")\n",
        "        else:\n",
        "            print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "# --------------------------\n",
        "# Salvar resultados em arquivo TXT\n",
        "# --------------------------\n",
        "with open(\"results.txt\", \"w\") as f:\n",
        "    f.write(\"Matriz de ConfusÃ£o\\n\")\n",
        "    f.write(\"==================\\n\")\n",
        "    f.write(f\"                Pred: Pos   Pred: Neg\\n\")\n",
        "    f.write(f\"Real: Pos   ->   VP={cm.VP:<6}  FN={cm.FN:<6}\\n\")\n",
        "    f.write(f\"Real: Neg   ->   FP={cm.FP:<6}  VN={cm.VN:<6}\\n\\n\")\n",
        "\n",
        "    f.write(\"MÃ©tricas\\n\")\n",
        "    f.write(\"========\\n\")\n",
        "    for k, v in m.items():\n",
        "        if k == \"Total\":\n",
        "            f.write(f\"{k}: {v}\\n\")\n",
        "        else:\n",
        "            f.write(f\"{k}: {v:.4f}\\n\")\n",
        "\n",
        "print(\"âœ… Resultados salvos em results.txt\")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# ðŸ”¢ Exemplo rÃ¡pido (troque os nÃºmeros livremente)\n",
        "# --------------------------\n",
        "cm = ConfusionMatrix(VP=90, VN=50, FP=10, FN=20)\n",
        "m = metrics_summary(cm)\n",
        "pretty_print(cm, m)\n",
        "\n",
        "# --------------------------\n",
        "# âœ… (Opcional) Checagem com scikit-learn para conferÃªncia\n",
        "# --------------------------\n",
        "try:\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "    # ReconstrÃ³i vetores y_true/y_pred a partir da matriz\n",
        "    y_true = np.array([1]*cm.VP + [1]*cm.FN + [0]*cm.VP + [0]*cm.VN)  # sÃ³ para formar vetor do tamanho certo\n",
        "    # Corrige: precisamos criar pares coerentes. Vamos gerar manualmente:\n",
        "    y_true = np.array([1]*cm.VP + [1]*cm.FN + [0]*cm.TN + [0]*cm.FP)\n",
        "except Exception:\n",
        "    pass\n"
      ]
    }
  ]
}